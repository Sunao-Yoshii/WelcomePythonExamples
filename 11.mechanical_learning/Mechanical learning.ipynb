{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習の入り口(scikit-learn)\n",
    "\n",
    "for Python 3.7.x\n",
    "\n",
    "## scikit-learn の読み込み\n",
    "\n",
    "import しないと始まりませんよね。  \n",
    "scukit-learn は `pip install -U scikit-learn` でインストールできます。\n",
    "\n",
    "以上！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、scikit-learn にはサンプルデータが既に含まれているので、そちらを使ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "iris_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データと検証データ\n",
    "\n",
    "データを全て学習に使ってしまった場合、どうやって作成した機械学習の妥当性を計測しましょう？  \n",
    "この問題を解決する為、一般的には `教師データ`, `検証データ` の二つに分離します。  \n",
    "だいたい 7:3 の比率ですが、データを無作為に分離する便利な機能があります。\n",
    "\n",
    "`train_test_split` という関数を利用すると、いい感じにデータを分離してくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分離したデータはほぼ純粋なマトリクスデータになっているので、このタイミングで `pandas` に食わせてしまいましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "iris_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ加工とロジスティック回帰\n",
    "\n",
    "植物であっても、例外的に大きなデータ、個体差はあるはずなので、ガクや花弁の大きさ以外に、その比率を事前に算出してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataframe['sepal rate'] = iris_dataframe['sepal length (cm)'] / iris_dataframe['sepal width (cm)']\n",
    "iris_dataframe['petal rate'] = iris_dataframe['petal length (cm)'] / iris_dataframe['petal width (cm)']\n",
    "iris_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dataframe = pd.DataFrame(X_test, columns=iris_dataset.feature_names)\n",
    "x_test_dataframe['sepal rate'] = x_test_dataframe['sepal length (cm)'] / x_test_dataframe['sepal width (cm)']\n",
    "x_test_dataframe['petal rate'] = x_test_dataframe['petal length (cm)'] / x_test_dataframe['petal width (cm)']\n",
    "x_test_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰を実際に行ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(iris_dataframe, y_train)\n",
    "Y_pred = logreg.predict(x_test_dataframe)\n",
    "acc_log = round(logreg.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sepal rate', 'petal rate'])\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "かなりいい数字が出てきましたね。  \n",
    "確かにガクと花弁の大きさには意味がある様です。\n",
    "\n",
    "### 機械学習アルゴリズムを実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# サポートベクタマシンで判定\n",
    "# 学修\n",
    "svc = SVC()\n",
    "svc.fit(iris_dataframe, y_train)\n",
    "\n",
    "# 検証\n",
    "Y_pred = svc.predict(x_test_dataframe)\n",
    "\n",
    "# 正答率確認\n",
    "acc_svc = round(svc.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# K近傍法\n",
    "# 学習\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(iris_dataframe, y_train)\n",
    "\n",
    "# 検証\n",
    "Y_pred = knn.predict(x_test_dataframe)\n",
    "\n",
    "# 正答率\n",
    "acc_knn = round(knn.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 単純ベイズ分類\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = gaussian.predict(x_test_dataframe)\n",
    "\n",
    "acc_gaussian = round(gaussian.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# パーセプトロン\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = perceptron.predict(x_test_dataframe)\n",
    "\n",
    "acc_perceptron = round(perceptron.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "# Linear SVC\n",
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = linear_svc.predict(x_test_dataframe)\n",
    "\n",
    "acc_linear_svc = round(linear_svc.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 最急降下法\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = sgd.predict(x_test_dataframe)\n",
    "\n",
    "acc_sgd = round(sgd.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 決定木\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = decision_tree.predict(x_test_dataframe)\n",
    "\n",
    "acc_decision_tree = round(decision_tree.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ランダムフォレスト\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(iris_dataframe, y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(x_test_dataframe)\n",
    "\n",
    "acc_random_forest = round(random_forest.score(iris_dataframe, y_train) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル比較\n",
    "\n",
    "どんなアルゴリズムが一番効果が出たのかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score': [acc_svc, acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
